{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7dc7fc",
   "metadata": {},
   "source": [
    "Fine-tuning with Python\n",
    "----------------------------\n",
    "\n",
    "The recommended way to do training is with the `main.py` script in ocp. One of the reasons for that is training often takes a long time and is better suited for queue systems like slurm. However, you can submit Python scripts too, and it is possible to run notebooks in Slurm too. Here we work out a proof of concept in training from Python and a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093139c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fairchem.core.common.utils import SeverityLevelBetween\n",
    "\n",
    "root = logging.getLogger()\n",
    "\n",
    "\n",
    "root.setLevel(logging.INFO)\n",
    "\n",
    "log_formatter = logging.Formatter(\n",
    "            \"%(asctime)s (%(levelname)s): %(message)s\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\",)\n",
    "\n",
    "# Send INFO to stdout\n",
    "handler_out = logging.FileHandler('out.txt', 'w')\n",
    "handler_out.addFilter(\n",
    "            SeverityLevelBetween(logging.INFO, logging.WARNING)\n",
    "        )\n",
    "handler_out.setFormatter(log_formatter)\n",
    "root.addHandler(handler_out)\n",
    "\n",
    "# Send WARNING (and higher) to stderr\n",
    "handler_err = logging.FileHandler('out.txt', 'w+')\n",
    "handler_err.setLevel(logging.WARNING)\n",
    "handler_err.setFormatter(log_formatter)\n",
    "root.addHandler(handler_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c905e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ase db ../../core/fine-tuning/oxides.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.models.model_registry import model_name_to_local_file\n",
    "\n",
    "checkpoint_path = model_name_to_local_file('GemNet-OC-S2EFS-OC20+OC22', local_cache='/tmp/ocp_checkpoints/')\n",
    "from fairchem.core.common.relaxation.ase_utils import OCPCalculator\n",
    "calc = OCPCalculator(checkpoint_path=checkpoint_path, trainer='forces', cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863da7eb",
   "metadata": {},
   "source": [
    "## Split the data into train, test, val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr train.db test.db val.db\n",
    "\n",
    "from fairchem.core.common.tutorial_utils import train_test_val_split\n",
    "\n",
    "train, test, val = train_test_val_split('../../core/fine-tuning/oxides.db')\n",
    "train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e550dc5",
   "metadata": {},
   "source": [
    "# Setup the training code\n",
    "\n",
    "We start by making the config.yml. We build this from the calculator checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da82123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.common.tutorial_utils import generate_yml_config\n",
    "\n",
    "yml = generate_yml_config(checkpoint_path, 'config.yml',\n",
    "                   delete=['slurm', 'cmd', 'logger', 'task', 'model_attributes',\n",
    "                           'optim.loss_force', # the checkpoint setting causes an error\n",
    "                           'dataset', 'test_dataset', 'val_dataset'],\n",
    "                   update={'gpus': 1,\n",
    "                           'optim.eval_every': 10,\n",
    "                           'optim.max_epochs': 1,\n",
    "                           'optim.batch_size': 4,\n",
    "                           'logger': 'tensorboard', # don't use wandb unless you already are logged in\n",
    "                           # Train data\n",
    "                           'dataset.train.src': 'train.db',\n",
    "                           'dataset.train.format': 'ase_db',\n",
    "                           'dataset.train.a2g_args.r_energy': True,\n",
    "                           'dataset.train.a2g_args.r_forces': True,\n",
    "                            # Test data - prediction only so no regression\n",
    "                           'dataset.test.src': 'test.db',\n",
    "                           'dataset.test.format': 'ase_db',\n",
    "                           'dataset.test.a2g_args.r_energy': False,\n",
    "                           'dataset.test.a2g_args.r_forces': False,\n",
    "                           # val data\n",
    "                           'dataset.val.src': 'val.db',\n",
    "                           'dataset.val.format': 'ase_db',\n",
    "                           'dataset.val.a2g_args.r_energy': True,\n",
    "                           'dataset.val.a2g_args.r_forces': True,\n",
    "                          })\n",
    "\n",
    "yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87470b",
   "metadata": {},
   "source": [
    "## Setup the training task\n",
    "\n",
    "This essentially allows several opportunities to define and override the config. You start with the base config.yml, and then via \"command-line\" arguments you specify changes you want to make.\n",
    "\n",
    "The code is build around `submitit`, which is often used with Slurm, but also works locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161119e",
   "metadata": {},
   "source": [
    "We have to mimic the `main.py` setup to get the arguments and config setup. Here is a minimal way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31021fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.common.flags import flags\n",
    "parser = flags.get_parser()\n",
    "args, args_override = parser.parse_known_args([\"--mode=train\",\n",
    "                                               \"--config-yml=config.yml\",\n",
    "                                               f\"--checkpoint={checkpoint_path}\",\n",
    "                                               \"--amp\"])\n",
    "args, args_override"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15050b2",
   "metadata": {},
   "source": [
    "Next, we build the first stage in our config. This starts with the file config.yml, then updates it with the args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.common.utils import build_config, new_trainer_context\n",
    "\n",
    "config = build_config(args=args, args_override={})\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37d956",
   "metadata": {},
   "source": [
    "# Run the training task\n",
    "\n",
    "It is still annoying that if your output is too large the notebook will not be able to be saved. On the other hand, it is annoying to simply capture the output.\n",
    "\n",
    "We are able to redirect most logging to a file above, but not all of it. The link below will open the file in a browser, and the subsequent cell captures all residual output. We do not need any of that, so it is ultimately discarded.\n",
    "\n",
    "Alternatively, you can open a Terminal and use `tail -f out.txt` to see the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, FileLink\n",
    "display(FileLink('out.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_trainer_context(config=config) as ctx:\n",
    "    config = ctx.config\n",
    "    task = ctx.task\n",
    "    trainer = ctx.trainer\n",
    "    task.setup(trainer)\n",
    "    task.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head out.txt\n",
    "! tail out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4466007",
   "metadata": {},
   "source": [
    "Now, you are all set to carry on with what ever subsequent analysis you want to do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
