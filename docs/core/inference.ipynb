{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d2e2b9",
   "metadata": {},
   "source": [
    "Fast batched inference\n",
    "------------------\n",
    "\n",
    "The ASE calculator is not necessarily the most efficient way to run a lot of computations. It is better to do a \"mass inference\" using a command line utility. We illustrate how to do that here.\n",
    "\n",
    "In this paper we computed about 10K different gold structures:\n",
    "\n",
    "Boes, J. R., Groenenboom, M. C., Keith, J. A., & Kitchin, J. R. (2016). Neural network and Reaxff comparison for Au properties. Int. J. Quantum Chem., 116(13), 979â€“987. http://dx.doi.org/10.1002/qua.25115\n",
    "\n",
    "You can retrieve the dataset below. In this notebook we learn how to do \"mass inference\" without an ASE calculator. You do this by creating a config.yml file, and running the `main.py` command line utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://figshare.com/ndownloader/files/11948267 -O data.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c804b",
   "metadata": {},
   "source": [
    "Inference on this file will be fast if we have a gpu, but if we don't this could take a while. To keep things fast for the automated builds, we'll just select the first 10 structures so it's still approachable with just a CPU.\n",
    "Comment or skip this block to use the whole dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv data.db full_data.db\n",
    "\n",
    "import ase.db\n",
    "import numpy as np\n",
    "\n",
    "with ase.db.connect('full_data.db') as full_db:\n",
    "  with ase.db.connect('data.db',append=False) as subset_db:\n",
    "\n",
    "    # Select 50 random points for the subset, ASE DB ids start at 1\n",
    "    for i in np.random.choice(list(range(1,len(full_db)+1)),size=50,replace=False):\n",
    "      atoms = full_db.get_atoms(f'id={i}', add_additional_information=True)\n",
    "\n",
    "      if 'tag' in atoms.info['key_value_pairs']:\n",
    "        atoms.info['key_value_pairs']['tag'] = int(atoms.info['key_value_pairs']['tag'])\n",
    "\n",
    "      for key in atoms.info[\"key_value_pairs\"]:\n",
    "        if atoms.info[\"key_value_pairs\"][key] == \"True\":\n",
    "            atoms.info[\"key_value_pairs\"][key] = True\n",
    "        elif atoms.info[\"key_value_pairs\"][key] == \"False\":\n",
    "            atoms.info[\"key_value_pairs\"][key] = False\n",
    "\n",
    "      subset_db.write(atoms, **atoms.info['key_value_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16091aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ase db data.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa10618c",
   "metadata": {},
   "source": [
    "You have to choose a checkpoint to start with. The newer checkpoints may require too much memory for this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be53616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.models.model_registry import available_pretrained_models\n",
    "print(available_pretrained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.models.model_registry import model_name_to_local_file\n",
    "\n",
    "checkpoint_path = model_name_to_local_file('GemNet-dT-S2EFS-OC22', local_cache='/tmp/ocp_checkpoints/')\n",
    "checkpoint_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d7a50",
   "metadata": {},
   "source": [
    "We have to update our configuration yml file with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e05336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.common.tutorial_utils import generate_yml_config\n",
    "yml = generate_yml_config(checkpoint_path, 'config.yml',\n",
    "                   delete=['cmd', 'logger', 'task', 'model_attributes',\n",
    "                           'dataset', 'slurm'],\n",
    "                   update={'amp': True,\n",
    "                           'gpus': 1,\n",
    "                           'task.prediction_dtype': 'float32',\n",
    "                           'logger':'tensorboard', # don't use wandb!\n",
    "                            # Test data - prediction only so no regression\n",
    "                           'dataset.test.src': 'data.db',\n",
    "                           'dataset.test.format': 'ase_db',\n",
    "                           'dataset.test.a2g_args.r_energy': False,\n",
    "                           'dataset.test.a2g_args.r_forces': False,\n",
    "                           'dataset.test.select_args.selection': 'natoms>5,xc=PBE',\n",
    "                          })\n",
    "\n",
    "yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda71e56",
   "metadata": {},
   "source": [
    "It is a good idea to redirect the output to a file. If the output gets too large here, the notebook may fail to save. Normally I would use a redirect like `2&>1`, but this does not work with the main.py method. An alternative here is to open a terminal and run it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa058cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture inference\n",
    "import time\n",
    "from fairchem.core.common.tutorial_utils import fairchem_main\n",
    "\n",
    "t0 = time.time()\n",
    "! python {fairchem_main()} --mode predict --config-yml {yml} --checkpoint {checkpoint_path} --amp\n",
    "print(f'Elapsed time = {time.time() - t0:1.1f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mass-inference.txt', 'wb') as f:\n",
    "    f.write(inference.stdout.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep \"Total time taken:\" 'mass-inference.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e6d16",
   "metadata": {},
   "source": [
    "The mass inference approach takes 1-2 minutes to run. See the output [here](./mass-inference.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ! grep \"  results_dir:\" mass-inference.txt\n",
    "d = results[0].split(':')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results = np.load(f'{d}/ocp_predictions.npz', allow_pickle=True)\n",
    "results.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e77a7",
   "metadata": {},
   "source": [
    "It is not obvious, but the data from mass inference is not in the same order. We have to get an id from the mass inference, and then \"resort\" the results so they are in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.array([int(r.split('_')[0]) for r in results['ids']])\n",
    "sind = np.argsort(inds)\n",
    "inds[sind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd3dc4",
   "metadata": {},
   "source": [
    "To compare this with the results, we need to get the energy data from the ase db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.db import connect\n",
    "db = connect('data.db')\n",
    "\n",
    "energies = np.array([row.energy for row in db.select('natoms>5,xc=PBE')])\n",
    "natoms = np.array([row.natoms for row in db.select('natoms>5,xc=PBE')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacad96",
   "metadata": {},
   "source": [
    "Now, we can see the predictions. They are only ok here; that is not surprising, the data set has lots of Au configurations that have never been seen by this model. Fine-tuning would certainly help improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(energies / natoms, results['energy'][sind] / natoms, 'b.')\n",
    "plt.xlabel('DFT')\n",
    "plt.ylabel('OCP');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66b7e3",
   "metadata": {},
   "source": [
    "# The ASE calculator way\n",
    "\n",
    "We include this here just to show that:\n",
    "\n",
    "1. We get the same results\n",
    "2. That this is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairchem.core.common.relaxation.ase_utils import OCPCalculator\n",
    "calc = OCPCalculator(checkpoint_path=checkpoint_path, cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "t0 = time.time()\n",
    "OCP, DFT = [], []\n",
    "for row in tqdm(db.select('natoms>5,xc=PBE')):\n",
    "    atoms = row.toatoms()\n",
    "    atoms.set_calculator(calc)\n",
    "    DFT += [row.energy / len(atoms)]\n",
    "    OCP += [atoms.get_potential_energy() / len(atoms)]\n",
    "print(f'Elapsed time {time.time() - t0:1.1} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c130cea",
   "metadata": {},
   "source": [
    "This takes at least twice as long as the mass-inference approach above. It is conceptually simpler though, and does not require resorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37555128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DFT, OCP, 'b.')\n",
    "plt.xlabel('DFT (eV/atom)')\n",
    "plt.ylabel('OCP (eV/atom)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99154790",
   "metadata": {},
   "source": [
    "# Comparing ASE calculator and main.py\n",
    "\n",
    "The results should be the same.\n",
    "\n",
    "It is worth noting the default precision of predictions is float16 with main.py, but with the ASE calculator the default precision is float32. Supposedly you can specify `--task.prediction_dtype=float32` at the command line to or specify it in the config.yml like we do above, but as of the tutorial this does not resolve the issue.\n",
    "\n",
    "As noted above (see also [Issue 542](https://github.com/FAIR-Chem/fairchem/issues/542)), the ASE calculator and main.py use different precisions by default, which can lead to small differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(results['energy'][sind] - OCP * natoms))  # MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(results['energy'][sind] - OCP * natoms), np.max(results['energy'][sind] - OCP * natoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704da2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results['energy'][sind] - OCP * natoms, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c7985",
   "metadata": {},
   "source": [
    "Here we see many of the differences are very small. 0.0078125 = 1 / 128, and these errors strongly suggest some kind of mixed precision is responsible for these differences. It is an open issue to remove them and identify where the cause is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(results['energy'][sind] - OCP * natoms)[0:400]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
