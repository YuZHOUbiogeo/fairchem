{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52c48de",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Training and evaluating custom models on OCP datasets\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "The [Open Catalyst Project](https://opencatalystproject.org/) consists of three distinct tasks:\n",
    "- Initial Structure to Relaxed Energy prediction (IS2RE)\n",
    "- Structure to Energy and Forces (S2EF)\n",
    "- Initial Structure to Relaxed Structure (IS2RS)\n",
    "\n",
    "This document is a tutorial for training and evaluating models\n",
    "for each of these tasks as well as generating submission files for the\n",
    "[evaluation server hosted on EvalAI](https://eval.ai/web/challenges/challenge-page/712/overview).\n",
    "\n",
    "`main.py` serves as the entry point to run any task. This script requires two command line\n",
    "arguments at a minimum:\n",
    "* `--mode MODE`: MODE can be `train`, `predict` or `run-relaxations` to train a model, make predictions\n",
    "using an existing model, or run machine learning based relaxations using an existing model, respectively.\n",
    "* `--config-yml PATH`: PATH is the path to a YAML configuration file. We use YAML files to supply all\n",
    "parameters to the script. The `configs` directory contains a number of example config files.\n",
    "\n",
    "Running `main.py` directly runs the model on a single CPU or GPU if one is available:\n",
    "```\n",
    "python main.py --mode train --config-yml configs/TASK/SIZE/MODEL/MODEL.yml\n",
    "```\n",
    "If you have multiple\n",
    "GPUs, you can use distributed data parallel training by running:\n",
    "```\n",
    "torchrun --standalone --nproc_per_node=8 main.py --distributed --num-gpus 8 [...]\n",
    "```\n",
    "`torchrun` launches multiple processes for distributed training. For more details, refer to the\n",
    "[official documentation](https://pytorch.org/docs/stable/elastic/run.html)\n",
    "\n",
    "If training with multiple GPUs, GPU load balancing may be used to evenly distribute a batch of variable system sizes across GPUs. Load balancing may either balance by number of atoms or number of neighbors. A `metadata.npz` file must be available in the dataset directory to take advantage of this feature. The following command will generate a  `metadata.npz` file and place it in the corresponding directory.\n",
    "```\n",
    "python scripts/make_lmdb_sizes.py --data-path data/s2ef/train/2M --num-workers 8\n",
    "```\n",
    "Load balancing is activated by default (in atoms mode). To change modes you can specify the following in your config:\n",
    "```\n",
    "optim:\n",
    "  load_balancing: neighbors\n",
    "```\n",
    "For more details, refer to [PR 267](https://github.com/FAIR-Chem/fairchem/pull/267).\n",
    "\n",
    "If you have access to a slurm cluster, we use the [submitit](https://github.com/facebookincubator/submitit) package to simplify multi-node distributed training:\n",
    "```\n",
    "python main.py --distributed --num-gpus 8 --num-nodes 6 --submit [...]\n",
    "```\n",
    "\n",
    "In the rest of this tutorial, we explain how to train models for each task.\n",
    "\n",
    "# OC20\n",
    "\n",
    "## Initial Structure to Relaxed Energy prediction (IS2RE)\n",
    "\n",
    "In the IS2RE tasks, the model takes the initial structure as an input and predicts the structureâ€™s adsorption energy\n",
    "in the relaxed state. To train a model for the IS2RE task, you can use the following in your configuration file:\n",
    "\n",
    "```yaml\n",
    "trainer: ocp\n",
    "\n",
    "dataset:\n",
    "  # Train data\n",
    "  train:\n",
    "    src: [Path to training data]\n",
    "    normalize_labels: True\n",
    "    # Mean and standard deviation of energies\n",
    "    target_mean: -0.969171404838562\n",
    "    target_std: 1.3671793937683105\n",
    "  # Val data (optional)\n",
    "  val:\n",
    "    src: [Path to validation data]\n",
    "  # Test data (optional)\n",
    "  test:\n",
    "    src: [Path to test data]\n",
    "```\n",
    "You can find examples configuration files in [`configs/is2re`](https://github.com/FAIR-Chem/fairchem/tree/main/src/fairchem/core/configs/is2re).\n",
    "\n",
    "To train a SchNet model for the IS2RE task on the 10k split, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fa102",
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --mode train --config-yml configs/is2re/10k/schnet/schnet.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de8107",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Training logs are stored in `logs/tensorboard/[TIMESTAMP]` where `[TIMESTAMP]` is\n",
    "the starting time-stamp of the run. You can monitor the training process by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67061b3f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir logs/tensorboard/[TIMESTAMP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf069833",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "At the end of training, the model checkpoint is stored in `checkpoints/[TIMESTAMP]/checkpoint.pt`.\n",
    "\n",
    "Next, run this model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d6e80",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "python main.py --mode predict --config-yml configs/is2re/10k/schnet/schnet.yml \\\n",
    "        --checkpoint checkpoints/[TIMESTAMP]/checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdc12d",
   "metadata": {},
   "source": [
    "The predictions are stored in `[RESULTS_DIR]/is2re_predictions.npz` and later used to create a submission file to be uploaded to EvalAI.\n",
    "\n",
    "### IS2RE Relaxations\n",
    "\n",
    "Alternatively, the IS2RE task may be approached by 2 methods as described in our paper:\n",
    "\n",
    "- Single Model: Relaxed energy predictions are extracted from relaxed structures generated via ML relaxations from a single model.\n",
    "\n",
    "    1. Train a S2EF model on both energy and forces as described [here](../core/model_training.md)\n",
    "    2. Using the trained S2EF model, run ML relaxations as described [here](../core/model_training.md). Ensure `traj_dir` is uniquely specified in the config as to save out the full trajectory. A sample config can be found [here](https://github.com/FAIR-Chem/fairchem/blob/main/src/fairchem/core/configs/s2ef/2M/dimenet_plus_plus/dpp_relax.yml). ** Note ** Relaxations on the complete val/test set may take upwards of 8hrs depending on your available hardware.\n",
    "    3. Prepare a submission file by running the following command:\n",
    "        ```\n",
    "        python scripts/make_submission_file.py --id path/to/id/traj_dir \\\n",
    "                --ood-ads path/to/ood_ads/traj_dir --ood-cat path/to/ood_cat/traj_dir \\\n",
    "                --ood-both path/to/ood_both/traj_dir --out-path submission_file.npz --is2re-relaxations\n",
    "        ```\n",
    "- Dual Model: Relaxed energy predictions are extracted from relaxed structures generated via ML relaxations from two models - one for running relaxations and one for making energy predictions.\n",
    "    1. Train two S2EF models, energy-only and force-only.\n",
    "    2. Using the trained force-only S2EF model, run ML relaxations as described previously. Ensure `traj_dir` is uniquely specified in the config as to save out the full trajectory. **Note** Relaxations on the complete val/test set may take upwards of 8hrs depending on your available hardware.\n",
    "    3. In order to make predictions via the energy-only model on the generated trajectories, LMDBs must be constructed via the following command:\n",
    "        ```\n",
    "        python scripts/preprocess_relaxed.py --id path/to/id/traj_dir \\\n",
    "              --ood-ads path/to/ood_ads/traj_dir --ood-cat path/to/ood_cat/traj_dir \\\n",
    "              --ood-both path/to/ood_both/traj_dir --out-path $DIR --num-workers $NUM_WORKERS\n",
    "        ```\n",
    "        Where `$DIR` specifies the directory to save generated LMDBs. A sub-directory will be created for each of the 4 splits in `$DIR`. `$NUM_WORKERS` is the number of data preprocessing cpu workers to be used.\n",
    "    4. Update your energy-only config to point the test set to the newly generated LMDBs. Using the trained energy-only S2EF model, generate predictions via `--mode predict` (as you would do for the general IS2RE/S2EF case).\n",
    "    5. Prepare a submission file by running the following command:\n",
    "        ```\n",
    "        python scripts/make_submission_file.py --id path/to/id/s2ef_predictions.npz \\\n",
    "                --ood-ads path/to/ood_ads/s2ef_predictions.npz --ood-cat path/to/ood_cat/s2ef_predictions.npz \\\n",
    "                --ood-both path/to/ood_both/s2ef_predictions.npz --out-path submission_file.npz \\\n",
    "                --is2re-relaxations --hybrid\n",
    "        ```\n",
    "## Structure to Energy and Forces (S2EF)\n",
    "\n",
    "In the S2EF task, the model takes the positions of the atoms as input and predicts the adsorption energy and per-atom\n",
    "forces as calculated by DFT. To train a model for the S2EF task, you can use the `OCPTrainer`\n",
    "and `TrajectoryLmdb` dataset by specifying the following in your configuration file:\n",
    "\n",
    "```yaml\n",
    "trainer: ocp\n",
    "\n",
    "dataset:\n",
    "  # Training data\n",
    "  train:\n",
    "    src: [Path to training data]\n",
    "    normalize_labels: True\n",
    "    # Mean and standard deviation of energies\n",
    "    target_mean: -0.7586356401443481\n",
    "    target_std: 2.981738567352295\n",
    "    # Mean and standard deviation of forces\n",
    "    grad_target_mean: 0.0\n",
    "    grad_target_std: 2.981738567352295\n",
    "  # Val data (optional)\n",
    "  val:\n",
    "    src: [Path to validation data]\n",
    "  # Test data (optional)\n",
    "  test:\n",
    "    src: [Path to test data]\n",
    "```\n",
    "You can find examples configuration files in [`configs/s2ef`](https://github.com/FAIR-Chem/fairchem/tree/main/src/fairchem/core/configs/s2ef).\n",
    "\n",
    "To train a SchNet model for the S2EF task on the 2M split using 2 GPUs, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d1c1e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=2 main.py \\\n",
    "        --mode train --config-yml configs/s2ef/2M/schnet/schnet.yml --num-gpus 2 --distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f65ce",
   "metadata": {},
   "source": [
    "Similar to the IS2RE task, tensorboard logs are stored in `logs/tensorboard/[TIMESTAMP]` and the\n",
    "checkpoint is stored in `checkpoints/[TIMESTAMP]/checkpoint.pt`.\n",
    "\n",
    "Next, run this model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b5f6c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "python main.py --mode predict --config-yml configs/s2ef/2M/schnet/schnet.yml \\\n",
    "        --checkpoint checkpoints/[TIMESTAMP]/checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7cacf",
   "metadata": {},
   "source": [
    "The predictions are stored in `[RESULTS_DIR]/ocp_predictions.npz` and later used to create a submission file to be uploaded to EvalAI.\n",
    "\n",
    "## Training OC20 models with total energies (IS2RE/S2EF)\n",
    "\n",
    "To train and validate an OC20 IS2RE/S2EF model on total energies instead of adsorption energies there are a number of\n",
    "required changes to the config. They include setting: `dataset: oc22_lmdb`, `prediction_dtype: float32`,\n",
    "`train_on_oc20_total_energies: True`, and `oc20_ref: path/to/oc20_ref.pkl` (see example below).\n",
    "Also, please note that our evaluation server does not currently support OC20 total energy models.\n",
    "\n",
    "```yaml\n",
    "task:\n",
    "  prediction_dtype: float32\n",
    "  ...\n",
    "\n",
    "dataset:\n",
    "  format: oc22_lmdb\n",
    "  train:\n",
    "    src: data/oc20/s2ef/train\n",
    "    normalize_labels: False\n",
    "    train_on_oc20_total_energies: True\n",
    "    # download at https://dl.fbaipublicfiles.com/opencatalystproject/data/oc22/oc20_ref.pkl\n",
    "    oc20_ref: path/to/oc20_ref.pkl\n",
    "  val:\n",
    "    src: data/oc20/s2ef/val_id\n",
    "    train_on_oc20_total_energies: True\n",
    "    oc20_ref: path/to/oc20_ref.pkl\n",
    "```\n",
    "\n",
    "## Overriding YAML config parameters from the command line\n",
    "\n",
    "There is some support for specifying arguments from the command line, such that\n",
    "they would override any parameter from the YAML configuration file. The parser\n",
    "for this relies on the [nesting level being correctly specified using a `.`\n",
    "separator](https://github.com/FAIR-Chem/fairchem/blob/main/src/fairchem/core/common/utils.py#L357).\n",
    "\n",
    "For example, to override the training dataset path via a command line argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcb8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py \\\n",
    "    --mode train\n",
    "    --config-yml configs/s2ef/2M/schnet/schnet.yml \\\n",
    "    --dataset.train.src=path/to/my/dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6445cc0",
   "metadata": {},
   "source": [
    "Or to update the initial learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e53d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py \\\n",
    "    --mode train\n",
    "    --config-yml configs/s2ef/2M/schnet/schnet.yml \\\n",
    "    --optim.lr_initial=3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1e248",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Initial Structure to Relaxed Structure (IS2RS)\n",
    "\n",
    "In the IS2RS task the model takes as input an initial structure and predicts the atomic positions in their\n",
    "final, relaxed state. This can be done by training a model to predict per-atom forces similar to the S2EF\n",
    "task and then running an iterative relaxation. Although we present an iterative approach, models that directly predict relaxed states are also possible. The iterative approach IS2RS task uses the same configuration files as the S2EF task `configs/s2ef` and follows the same training scheme above.\n",
    "\n",
    "To perform an iterative relaxation, ensure the following is added to the configuration files of the models you wish to run relaxations on:\n",
    "```yaml\n",
    "# Relaxation options\n",
    "relax_dataset:\n",
    "  src: data/is2re/all/val_id/data.lmdb # path to lmdb of systems to be relaxed (uses same lmdbs as is2re)\n",
    "write_pos: True\n",
    "relaxation_steps: 300\n",
    "relax_opt:\n",
    "  maxstep: 0.04\n",
    "  memory: 50\n",
    "  damping: 1.0\n",
    "  alpha: 70.0\n",
    "  traj_dir: \"trajectories\" # specify directory you wish to log the entire relaxations, suppress otherwise\n",
    "```\n",
    "\n",
    "After training, relaxations can be run by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca135e22",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "python main.py --mode run-relaxations --config-yml configs/s2ef/2M/schnet/schnet.yml \\\n",
    "        --checkpoint checkpoints/[TIMESTAMP]/checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a2b2b",
   "metadata": {},
   "source": [
    "The relaxed structure positions are stored in `[RESULTS_DIR]/relaxed_positions.npz` and later used to create a submission file to be uploaded to EvalAI. Predicted trajectories are stored in `trajectories` directory for those interested in analyzing the complete relaxation trajectory.\n",
    "\n",
    "## Create EvalAI OC20 submission files\n",
    "\n",
    "EvalAI expects results to be structured in a specific format for a submission to be successful. A submission must contain results from the 4 different splits - in distribution (id), out of distribution adsorbate (ood ads), out of distribution catalyst (ood cat), and out of distribution adsorbate and catalyst (ood both). Constructing the submission file for each of the above tasks is as follows:\n",
    "\n",
    "### S2EF/IS2RE:\n",
    "1. Run predictions `--mode predict` on all 4 splits, generating `[s2ef/is2re]_predictions.npz` files for each split.\n",
    "2. Run the following command:\n",
    "    ```bash\n",
    "    python make_submission_file.py --id path/to/id/file.npz --ood-ads path/to/ood_ads/file.npz \\\n",
    "    --ood-cat path/to/ood_cat/file.npz --ood-both path/to/ood_both/file.npz --out-path submission_file.npz\n",
    "    ```\n",
    "   Where `file.npz` corresponds to the respective `[s2ef/is2re]_predictions.npz` files generated for the corresponding task. The final submission file will be written to `submission_file.npz` (rename accordingly).\n",
    "3. Upload `submission_file.npz` to EvalAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5088d",
   "metadata": {},
   "source": [
    "### IS2RS:\n",
    "1. Ensure `write_pos: True` is included in your configuration file. Run relaxations `--mode run-relaxations` on all 4 splits, generating `relaxed_positions.npz` files for each split.\n",
    "2. Run the following command:\n",
    "    ```bash\n",
    "    python make_submission_file.py --id path/to/id/relaxed_positions.npz --ood-ads path/to/ood_ads/relaxed_positions.npz \\\n",
    "    --ood-cat path/to/ood_cat/relaxed_positions.npz --ood-both path/to/ood_both/relaxed_positions.npz --out-path is2rs_submission.npz\n",
    "    ```\n",
    "   The final submission file will be written to `is2rs_submission.npz` (rename accordingly).\n",
    "3. Upload `is2rs_submission.npz` to EvalAI.\n",
    "\n",
    "# OC22\n",
    "\n",
    "## Initial Structure to Total Relaxed Energy (IS2RE-Total)\n",
    "\n",
    "For the IS2RE-Total task, the model takes the initial structure as input and predicts the total DFT energy of the relaxed structure. This task is more general and more challenging than the original OC20 IS2RE task that predicts adsorption energy.\n",
    "To train an OC22 IS2RE-Total model use the `OC22LmdbDataset` by including these lines in your configuration file:\n",
    "\n",
    "```yaml\n",
    "dataset:\n",
    "  format: oc22_lmdb # Use the OC22LmdbDataset\n",
    "  ...\n",
    "```\n",
    "You can find examples configuration files in [`configs/oc22/is2re`](https://github.com/FAIR-Chem/fairchem/tree/main/src/fairchem/core/configs/oc22/is2re).\n",
    "\n",
    "## Structure to Total Energy and Forces (S2EF-Total)\n",
    "\n",
    "The S2EF-Total task takes a structure and predicts the total DFT energy and per-atom forces. This differs from the\n",
    "original OC20 S2EF task because it predicts total energy instead of adsorption energy.\n",
    "To train an OC22 S2EF-Total model the OC22LmdbDataset by including these lines in your configuration file:\n",
    "\n",
    "```yaml\n",
    "dataset:\n",
    "  format: oc22_lmdb # Use the OC22LmdbDataset\n",
    "  ...\n",
    "```\n",
    "You can find examples configuration files in [`configs/oc22/s2ef`](https://github.com/FAIR-Chem/fairchem/tree/main/src/fairchem/core/configs/oc22/s2ef).\n",
    "\n",
    "## Joint Training\n",
    "\n",
    "Training on OC20 total energies whether independently or jointly with OC22 requires a path to the `oc20_ref` (download link provided below) to be specified in the configuration file. These are necessary to convert OC20 adsorption energies into their corresponding total energies. The following changes in the configuration file capture these changes:\n",
    "\n",
    "```yaml\n",
    "dataset:\n",
    "  format: oc22_lmdb\n",
    "  ...\n",
    "\n",
    "dataset:\n",
    "  train:\n",
    "    src: data/oc20+oc22/s2ef/train\n",
    "    normalize_labels: False\n",
    "    train_on_oc20_total_energies: True\n",
    "    #download at https://dl.fbaipublicfiles.com/opencatalystproject/data/oc22/oc20_ref.pkl\n",
    "    oc20_ref: path/to/oc20_ref.pkl\n",
    "  val:\n",
    "    src: data/oc22/s2ef/val_id\n",
    "    train_on_oc20_total_energies: True\n",
    "    oc20_ref: path/to/oc20_ref.pkl\n",
    "```\n",
    "\n",
    "You can find an example configuration file at [configs/oc22/s2ef/base_joint.yml](https://github.com/FAIR-Chem/fairchem/blob/main/src/fairchem/core/configs/oc22/s2ef/base_joint.yml)\n",
    "\n",
    "## Create EvalAI OC22 submission files\n",
    "\n",
    "EvalAI expects results to be structured in a specific format for a submission to be successful. A submission must contain results from the 2 different splits - in distribution (id) and out of distribution (ood). Construct submission files for the OC22 S2EF-Total/IS2RE-Total tasks as follows:\n",
    "\n",
    "### S2EF-Total/IS2RE-Total:\n",
    "1. Run predictions `--mode predict` on both the id and ood splits, generating `[s2ef/is2re]_predictions.npz` files for each split.\n",
    "2. Run the following command:\n",
    "    ```bash\n",
    "    python make_submission_file.py --dataset OC22 --id path/to/id/file.npz --ood path/to/ood_ads/file.npz --out-path submission_file.npz\n",
    "    ```\n",
    "   Where `file.npz` corresponds to the respective `[s2ef/is2re]_predictions.npz` files generated for the corresponding task. The final submission file will be written to `submission_file.npz` (rename accordingly). The `dataset` argument specifies which dataset is being considered â€” this only needs to be set for OC22 predictions because OC20 is the default.\n",
    "3. Upload `submission_file.npz` to EvalAI."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
